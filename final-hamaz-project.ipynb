{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport re\nfrom nltk.corpus import stopwords\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix\n\nfrom sklearn import preprocessing\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, MaxPool1D, Dropout, Dense, GlobalMaxPooling1D, Embedding, Activation\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/hate-speech-detection/toxic_train.csv')\ntest_data = pd.read_csv('/kaggle/input/hate-speech-detection/toxic_test.csv')","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# drop unnamed column\n\ntrain_data = train_data.drop(columns=['Unnamed: 0'])\ntrain_data.head()","metadata":{"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                        comment_text  toxic\n0  Explanation\\r\\nWhy the edits made under my use...      0\n1  D'aww! He matches this background colour I'm s...      0\n2  Hey man, I'm really not trying to edit war. It...      0\n3  \"\\r\\nMore\\r\\nI can't make any real suggestions...      0\n4  You, sir, are my hero. Any chance you remember...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment_text</th>\n      <th>toxic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Explanation\\r\\nWhy the edits made under my use...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"\\r\\nMore\\r\\nI can't make any real suggestions...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_data = test_data.drop(columns=['Unnamed: 0'])\ntest_data.head()","metadata":{"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                        comment_text  toxic\n0  Thank you for understanding. I think very high...      0\n1                   :Dear god this site is horrible.      0\n2  \"::: Somebody will invariably try to add Relig...      0\n3  \" \\r\\n\\r\\n It says it right there that it IS a...      0\n4  \" \\r\\n\\r\\n == Before adding a new product to t...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment_text</th>\n      <th>toxic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Thank you for understanding. I think very high...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>:Dear god this site is horrible.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"::: Somebody will invariably try to add Relig...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\" \\r\\n\\r\\n It says it right there that it IS a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\" \\r\\n\\r\\n == Before adding a new product to t...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_text(sen):\n    # lower the character\n    sentence = sen.lower()\n    \n    # Remove punctuations and numbers\n    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n\n    # Single character removal\n    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n\n    # Removing multiple spaces\n    sentence = re.sub(r'\\s+', ' ', sentence)\n    \n    stops = stopwords.words('english')\n    \n    for word in sentence.split():\n        if word in stops:\n            sentence = sentence.replace(word, '')\n    return sentence","metadata":{"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# preprocess data\n\ntrain_data['comment_text'] = train_data['comment_text'].apply(lambda x : preprocess_text(x))\ntest_data['comment_text'] = test_data['comment_text'].apply(lambda x : preprocess_text(x))","metadata":{"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_data['comment_text']","metadata":{"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"0         Explani Why edits ade usernae Hardcore Metalli...\n1         D aww He atches background colour seeingly stu...\n2         Hey  really trying edit war It guy consttly re...\n3          Me make al suggestis improvent wded secti sta...\n4                    You sir hero Any chance remember page \n                                ...                        \n159566     And second time askg view completely contradi...\n159567       You ashamed That horrible thing put talk page \n159568    Spitzer Umm theres actual article prostitution...\n159569    And looks like actually put speedy first versi...\n159570     And really think underst came idea bad right ...\nName: comment_text, Length: 159571, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"test_data['comment_text']","metadata":{"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"0        Thank understing think highly would revert wit...\n1                                  Dear god site horrible \n2         Somebody variably try add Religi Really You m...\n3         It says right IS type The Type stution needed...\n4         Before adding new product list make sure rele...\n                               ...                        \n63973     Jeroe see never got around surpred looked exa...\n63974     Lucky bastard http wikimediafoundation org wi...\n63975                 shame You want speak gays romanians \n63976    MEL GIBSON IS NAZI BITCH WHO MAKES SHITTY MOVI...\n63977     Unicorn lair dcovery Supposedly unicorn lair ...\nName: comment_text, Length: 63978, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\ntweet = train_data['comment_text']\ntokenizer = Tokenizer(num_words=5000)\ntokenizer.fit_on_texts(tweet)\nvocab_size = len(tokenizer.word_index) + 1\nencoded_docs = tokenizer.texts_to_sequences(tweet)\npadded_sequence = pad_sequences(encoded_docs, maxlen=200)","metadata":{"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"y = train_data['toxic'].values","metadata":{"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# print(tokenizer.word_index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tweet[0])\nprint(encoded_docs[0])","metadata":{"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Explani Why edits ade usernae Hardcore Metallica Fan reverted They vandaliss closure GAs voted New York Dolls FAC And please reove teple talk page since retired \n[118, 147, 709, 1242, 309, 245, 2429, 3176, 35, 1997, 1314, 37, 15, 2891, 1783, 7, 3, 370, 4776]\n","output_type":"stream"}]},{"cell_type":"code","source":"padded_sequence[0]","metadata":{"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,    0,  118,  147,  709, 1242,  309,  245,\n       2429, 3176,   35, 1997, 1314,   37,   15, 2891, 1783,    7,    3,\n        370, 4776], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"# Build the model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import SpatialDropout1D\nfrom tensorflow.keras.layers import Embedding\nembedding_vector_length = 32\nmodel = Sequential()\nmodel.add(Embedding(vocab_size, embedding_vector_length,     \n                                     input_length=2000) )\nmodel.add(SpatialDropout1D(0.25))\nmodel.add(LSTM(50, dropout=0.5, recurrent_dropout=0.5))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam', \n                           metrics=['accuracy'])\nprint(model.summary())","metadata":{"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 2000, 32)          7624096   \n_________________________________________________________________\nspatial_dropout1d_1 (Spatial (None, 2000, 32)          0         \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 50)                16600     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 50)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 51        \n=================================================================\nTotal params: 7,640,747\nTrainable params: 7,640,747\nNon-trainable params: 0\n_________________________________________________________________\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit(padded_sequence,y,\n                  validation_split=0.2, epochs=3, batch_size=1024)","metadata":{"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Epoch 1/3\n125/125 [==============================] - 148s 1s/step - loss: 0.3282 - accuracy: 0.9033 - val_loss: 0.1798 - val_accuracy: 0.9350\nEpoch 2/3\n125/125 [==============================] - 137s 1s/step - loss: 0.1601 - accuracy: 0.9442 - val_loss: 0.1361 - val_accuracy: 0.9530\nEpoch 3/3\n125/125 [==============================] - 149s 1s/step - loss: 0.1315 - accuracy: 0.9543 - val_loss: 0.1292 - val_accuracy: 0.9552\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.models import load_model\nmodel.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n# del model  # deletes the existing model\n# returns a compiled model\n# identical to the previous one","metadata":{"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"new_model = load_model('my_model.h5')","metadata":{"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"test_word =\"shame on you\"\ntw = tokenizer.texts_to_sequences([test_word])\ntw = pad_sequences(tw,maxlen=200)\nprediction = int(new_model.predict(tw).round().item())\n","metadata":{"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"prediction","metadata":{"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]}]}